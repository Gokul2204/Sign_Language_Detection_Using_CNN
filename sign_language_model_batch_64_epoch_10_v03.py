# -*- coding: utf-8 -*-
"""Sign_Language_Model_Batch_64_Epoch_10_V03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzkLtjuhtYmPdVZJWvLvFMPeao0c_xar

# Singn_Language_Detection_Main_Code

**Importing Libraries for Sign Language Detection**

This section imports all the necessary libraries required for building, training, and evaluating a sign language detection model. The libraries include:
*   **Numpy and Pandas** for data manipulation and analysis.
*   **Matplotlib and Seaborn** for data visualization.
*   **TensorFlow and Keras** for constructing and training neural network models.
*   **Scikit-learn** for model evaluation metrics.
*   **OpenCV** for image processing tasks.
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# TensorFlow and Keras for building and training the neural network
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
from tensorflow.keras.utils import to_categorical

# Sklearn for performance metrics and preprocessing
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.preprocessing import LabelBinarizer

# OpenCV for image processing
import cv2

# Suppress the specific warning
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module='tensorflow.keras.preprocessing.image')

"""**Exploring and Visualizing Sign Language Dataset**

This code segment loads and explores the sign language dataset, consisting of both training and test data.
*   Loading and Checking Data
*   Checking Duplicates
*   Visualizing Class Distribution





"""

# Loading and Checking Train Data
reference_train_data = pd.read_csv('/content/sign_mnist_train.csv')
print('reference_train_data_shape :', reference_train_data.shape)
print('Null_Values :' ,reference_train_data.isnull().sum().sum()) # To check null values in the data set
reference_train_data.info()
reference_train_data.head()

# Loading and Checking Test Data
reference_test_data = pd.read_csv('/content/sign_mnist_test.csv')
print('reference_test_data_shape :', reference_test_data.shape)
print('Null_Values :' ,reference_test_data.isnull().sum().sum()) # To check null values in the data set
reference_test_data.info()
reference_test_data.head()

# Checking Duplicates
print("train_duplicate_values : ", reference_train_data.duplicated().sum()) # To check duplicate values in the train data set
print("test_duplicate_values : ", reference_test_data.duplicated().sum()) # To check duplicate values in the test data set

#Visualizing Class Distribution
# Set up the figure with two subplots (1 row, 2 columns)
fig, axs = plt.subplots(1, 2, figsize=(12, 6))

# Plot for training data
sns.countplot(data=reference_train_data, x="label", ax=axs[0])
axs[0].set_title('Train Data')

# Plot for test data
sns.countplot(data=reference_test_data, x="label", ax=axs[1])
axs[1].set_title('Test Data')

# Adjust layout and display the plot
plt.tight_layout()
plt.show()

"""**Loading and Preprocessing Sign Language Dataset**

This function and subsequent code segment load and preprocess the sign language dataset from CSV files for training and testing purposes.

"""

# Function to load data from CSV
def load_data_from_csv(csv_file):
    data = pd.read_csv(csv_file)
    labels = data.iloc[:, 0]  # Extracting the Lables from the data set --> First column of data set
    images = data.iloc[:, 1:].values  # Extracting the Pixels from the data set --> Rest of the columns
    images = images.reshape(-1, 28, 28, 1) # Reshape to 28x28 and add channel dimension and normalization
    return images, labels

# # Function to load data from CSV
# def load_data_from_csv(csv_file):
#     data = pd.read_csv(csv_file)
#     labels = data.iloc[:, 0]  # Extracting the Lables from the data set --> First column of data set
#     images = data.iloc[:, 1:].values  # Extracting the Pixels from the data set --> Rest of the columns
#     return images, labels

# Load training and testing data
train_images, train_labels = load_data_from_csv('/content/sign_mnist_train.csv')
test_images, test_labels = load_data_from_csv('/content/sign_mnist_test.csv')

# Normalize the images with maximum pixel value 255.0
train_images = train_images / 255.0
test_images = test_images / 255.0

# train_images = train_images.reshape(-1, 28, 28, 1)  # Reshape to 28x28 and add channel dimension
# test_images = test_images.reshape(-1, 28, 28, 1)  # Reshape to 28x28 and add channel dimension

# Label Encoding
label_binarizer = LabelBinarizer()
train_labels = label_binarizer.fit_transform(train_labels)
test_labels = label_binarizer.transform(test_labels)

print("train_image_shape :" ,train_images.shape)
print("train_label_shape :" ,train_labels.shape)
print("test_image_shape :" ,test_images.shape)
print("test_label_shape :" ,test_labels.shape)

"""**Verifying Training Dataset Images and Labels**

This code segment allows you to verify individual images and their corresponding labels from the training dataset interactively
"""

# Verification of train data set image and lable
image_index =int(input()) # Index input
plt.imshow(train_images[image_index],cmap='gray') # Image
plt.title(str(train_labels[image_index]))  # Label
plt.show()

"""**Data Augmentation Configuration**

This code snippet configures an "ImageDataGenerator" object for data augmentation, which is crucial for increasing the diversity of training examples without collecting additional data.
"""

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=False
)

"""**Convolutional Neural Network Model Architecture**

This code segment defines a Convolutional Neural Network (CNN) model using TensorFlow's Keras API.

**Model Architecture:**
*   Convolutional Layers
*   Normalization and Pooling
*   Stacking Convolutional Layers
*   Flattening and Dense Layers
*   Batch Normalization and Dropout
*   Output Layer

This CNN architecture is designed for the sign language detection task, incorporating convolutional layers for feature extraction, pooling layers for spatial downsampling, dropout layers for regularization, and fully connected layers for classification. The model aims to learn and classify hand signs represented in the dataset effectively.



"""

# Model Building
model = Sequential([
    Input(shape=(28, 28, 1)),
    Conv2D(32, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((3, 3)),
    Dropout(0.2),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.2),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    BatchNormalization(),
    Dropout(0.5),

    Dense(24, activation='softmax')
])

print(train_images.shape, train_images.dtype)
print(train_labels.shape, train_labels.dtype)
print(test_images.shape, test_images.dtype)
print(test_labels.shape, test_labels.dtype)

"""**Compiling the Convolutional Neural Network Model**

This code segment compiles the previously defined Convolutional Neural Network (CNN) model using TensorFlow's Keras API.

Compiling the model configures it for training by specifying the optimizer, loss function, and evaluation metrics. This setup prepares the CNN model to learn from the training data and optimize its performance based on the specified objectives in the sign language detection project.
"""

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""**Custom Callback for F1 Score Calculation**

The **"F1ScoreCallback"** class is a custom TensorFlow Keras callback designed to compute and print the weighted F1 score at the end of each epoch during model training. This helps assess the model's performance based on precision and recall metrics, providing valuable insights into its effectiveness for the sign language detection task.
"""

# Custom callback to calculate F1 score for each epoch
class F1ScoreCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        predictions = model.predict(test_images)
        predicted_labels = np.argmax(predictions, axis=1)
        true_labels = np.argmax(test_labels, axis=1)
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        print(f"Epoch {epoch+1} - F1 Score: {f1:.2f}")

"""**Training the Convolutional Neural Network Model**

This code trains the CNN model using augmented data batches generated by **"datagen.flow()"**, validates the model's performance using the original test dataset, and prints the F1 score after each epoch using a custom callback. It aims to optimize the model's ability to classify sign language images accurately over multiple training iterations.
"""

# Model Training
history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),
                    validation_data=(test_images, test_labels),
                    epochs=10,
                    callbacks=[F1ScoreCallback()])

"""**Evaluating the Trained Convolutional Neural Network Model**

This code snippet assesses the CNN model's ability to generalize to unseen data by evaluating its performance on the independent test dataset. It provides a quantitative measure of the model's accuracy in classifying sign language images, indicating how well the model has learned and generalized from the training data.
"""

# Model Evaluation
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test accuracy: {test_acc}")

"""**Classification Report and Confusion Matrix for Model Evaluation**
*   The classification report provides detailed metrics for evaluating the model's
performance on each class in the dataset.
*   The confusion matrix visually represents the model's predictions compared to the true labels, highlighting any patterns or discrepancies in classification accuracy across different classes.



"""

# Classification Report and Confusion Matrix
predictions = model.predict(test_images)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.argmax(test_labels, axis=1)

# Convert label binarizer classes to list of strings
target_names = [str(class_label) for class_label in label_binarizer.classes_]

print(classification_report(true_labels, predicted_labels, target_names=target_names))

#Confusion_Matrix
cm = confusion_matrix(true_labels, predicted_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_binarizer.classes_, yticklabels=label_binarizer.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""**Model Saving**

Saving the model allows you to reuse it later for inference, deployment in applications, or further training. The HDF5 format preserves the model's architecture and weights, making it easy to load and use in different environments that support Keras or TensorFlow.
"""

def plot_metrics(history):
    plt.figure(figsize=(12, 5))

    # Plotting model accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plotting model loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_metrics(history)

# Save the model
model.save('Sign_Language_Model_Batch_64_Epoch_10_V03.h5')